{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T23:34:34.896766Z",
     "start_time": "2024-12-10T23:34:16.518177Z"
    }
   },
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.  Set up Asyncio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ceb2f5e08b31afb"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T23:35:00.395532Z",
     "start_time": "2024-12-10T23:35:00.387536Z"
    }
   },
   "id": "3a0478bfab82efd7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Define the LLM, the embedding model and re-ranker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f8ba8f42fc8f90b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2:1b\", request_timeout=180.0)\n",
    "\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "rerank = SentenceTransformerRerank(model=\"BAAI/bge-reranker-base\", top_n=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-11T01:58:13.070489Z"
    }
   },
   "id": "f9732abbb58922d2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T23:36:49.008644Z",
     "start_time": "2024-12-10T23:36:48.966329Z"
    }
   },
   "id": "ea54818a81119034"
  },
  {
   "cell_type": "markdown",
   "source": [
    " 3. Read the documents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b2be07eb9ec1061"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "input_dir_path = './docs/paul_graham'\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "            input_dir = input_dir_path,\n",
    "            required_exts=[\".txt\"],\n",
    "            recursive=True\n",
    "        )\n",
    "docs = loader.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T23:38:45.568849Z",
     "start_time": "2024-12-10T23:38:45.514858Z"
    }
   },
   "id": "4d9b059fee5caef1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Set up the Qdrant vector database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59e6936198d015f"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m vector_store \u001B[38;5;241m=\u001B[39m QdrantVectorStore(client\u001B[38;5;241m=\u001B[39mclient,\n\u001B[1;32m      3\u001B[0m                                  collection_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument_chat\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m storage_context \u001B[38;5;241m=\u001B[39m StorageContext\u001B[38;5;241m.\u001B[39mfrom_defaults(vector_store\u001B[38;5;241m=\u001B[39mvector_store)\n\u001B[0;32m----> 5\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[43mVectorStoreIndex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mstorage_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_context\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/base.py:119\u001B[0m, in \u001B[0;36mBaseIndex.from_documents\u001B[0;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m     docstore\u001B[38;5;241m.\u001B[39mset_document_hash(doc\u001B[38;5;241m.\u001B[39mget_doc_id(), doc\u001B[38;5;241m.\u001B[39mhash)\n\u001B[1;32m    112\u001B[0m nodes \u001B[38;5;241m=\u001B[39m run_transformations(\n\u001B[1;32m    113\u001B[0m     documents,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    114\u001B[0m     transformations,\n\u001B[1;32m    115\u001B[0m     show_progress\u001B[38;5;241m=\u001B[39mshow_progress,\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    117\u001B[0m )\n\u001B[0;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransformations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransformations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/vector_store/base.py:76\u001B[0m, in \u001B[0;36mVectorStoreIndex.__init__\u001B[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embed_model \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     70\u001B[0m     resolve_embed_model(embed_model, callback_manager\u001B[38;5;241m=\u001B[39mcallback_manager)\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m embed_model\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m Settings\u001B[38;5;241m.\u001B[39membed_model\n\u001B[1;32m     73\u001B[0m )\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insert_batch_size \u001B[38;5;241m=\u001B[39m insert_batch_size\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_struct\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_struct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobjects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobjects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransformations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransformations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/base.py:77\u001B[0m, in \u001B[0;36mBaseIndex.__init__\u001B[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index_struct \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m     nodes \u001B[38;5;241m=\u001B[39m nodes \u001B[38;5;129;01mor\u001B[39;00m []\n\u001B[0;32m---> 77\u001B[0m     index_struct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_index_from_nodes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mobjects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m     79\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_struct \u001B[38;5;241m=\u001B[39m index_struct\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_storage_context\u001B[38;5;241m.\u001B[39mindex_store\u001B[38;5;241m.\u001B[39madd_index_struct(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_struct)\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/vector_store/base.py:310\u001B[0m, in \u001B[0;36mVectorStoreIndex.build_index_from_nodes\u001B[0;34m(self, nodes, **insert_kwargs)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(content_nodes) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(nodes):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSome nodes are missing content, skipping them...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_index_from_nodes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minsert_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/vector_store/base.py:279\u001B[0m, in \u001B[0;36mVectorStoreIndex._build_index_from_nodes\u001B[0;34m(self, nodes, **insert_kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m     run_async_tasks(tasks)\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 279\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_nodes_to_index\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_struct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_show_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minsert_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m index_struct\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/vector_store/base.py:232\u001B[0m, in \u001B[0;36mVectorStoreIndex._add_nodes_to_index\u001B[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m nodes_batch \u001B[38;5;129;01min\u001B[39;00m iter_batch(nodes, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insert_batch_size):\n\u001B[0;32m--> 232\u001B[0m     nodes_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_node_with_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    233\u001B[0m     new_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vector_store\u001B[38;5;241m.\u001B[39madd(nodes_batch, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minsert_kwargs)\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vector_store\u001B[38;5;241m.\u001B[39mstores_text \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store_nodes_override:\n\u001B[1;32m    236\u001B[0m         \u001B[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001B[39;00m\n\u001B[1;32m    237\u001B[0m         \u001B[38;5;66;03m# we need to add the nodes to the index struct and document store\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/vector_store/base.py:139\u001B[0m, in \u001B[0;36mVectorStoreIndex._get_node_with_embedding\u001B[0;34m(self, nodes, show_progress)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_node_with_embedding\u001B[39m(\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    129\u001B[0m     nodes: Sequence[BaseNode],\n\u001B[1;32m    130\u001B[0m     show_progress: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    131\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BaseNode]:\n\u001B[1;32m    132\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m    Get tuples of id, node, and embedding.\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    137\u001B[0m \n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 139\u001B[0m     id_to_embed_map \u001B[38;5;241m=\u001B[39m \u001B[43membed_nodes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embed_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    143\u001B[0m     results \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m nodes:\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/indices/utils.py:148\u001B[0m, in \u001B[0;36membed_nodes\u001B[0;34m(nodes, embed_model, show_progress)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m         id_to_embed_map[node\u001B[38;5;241m.\u001B[39mnode_id] \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39membedding\n\u001B[0;32m--> 148\u001B[0m new_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43membed_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_text_embedding_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts_to_embed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m new_id, text_embedding \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(ids_to_embed, new_embeddings):\n\u001B[1;32m    153\u001B[0m     id_to_embed_map[new_id] \u001B[38;5;241m=\u001B[39m text_embedding\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py:670\u001B[0m, in \u001B[0;36mBoundFunctionWrapper.__call__\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    667\u001B[0m             wrapped \u001B[38;5;241m=\u001B[39m PartialCallableObjectProxy(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__wrapped__, instance)\n\u001B[1;32m    668\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_wrapper(wrapped, instance, newargs, kwargs)\n\u001B[0;32m--> 670\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_self_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__wrapped__\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_self_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m            \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_binding \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcallable\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_instance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    675\u001B[0m         \u001B[38;5;66;03m# This situation can occur where someone is calling the\u001B[39;00m\n\u001B[1;32m    676\u001B[0m         \u001B[38;5;66;03m# instancemethod via the class type and passing the instance as\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    679\u001B[0m         \u001B[38;5;66;03m# the wrapped function using a partial so the wrapper doesn't\u001B[39;00m\n\u001B[1;32m    680\u001B[0m         \u001B[38;5;66;03m# see anything as being different.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    318\u001B[0m             _logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 321\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio\u001B[38;5;241m.\u001B[39mFuture):\n\u001B[1;32m    323\u001B[0m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[1;32m    324\u001B[0m         new_future \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mensure_future(result)\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/base/embeddings/base.py:335\u001B[0m, in \u001B[0;36mBaseEmbedding.get_text_embedding_batch\u001B[0;34m(self, texts, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m    326\u001B[0m dispatcher\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    327\u001B[0m     EmbeddingStartEvent(\n\u001B[1;32m    328\u001B[0m         model_dict\u001B[38;5;241m=\u001B[39mmodel_dict,\n\u001B[1;32m    329\u001B[0m     )\n\u001B[1;32m    330\u001B[0m )\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    332\u001B[0m     CBEventType\u001B[38;5;241m.\u001B[39mEMBEDDING,\n\u001B[1;32m    333\u001B[0m     payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mSERIALIZED: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_dict()},\n\u001B[1;32m    334\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m event:\n\u001B[0;32m--> 335\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_text_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcur_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    336\u001B[0m     result_embeddings\u001B[38;5;241m.\u001B[39mextend(embeddings)\n\u001B[1;32m    337\u001B[0m     event\u001B[38;5;241m.\u001B[39mon_end(\n\u001B[1;32m    338\u001B[0m         payload\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m    339\u001B[0m             EventPayload\u001B[38;5;241m.\u001B[39mCHUNKS: cur_batch,\n\u001B[1;32m    340\u001B[0m             EventPayload\u001B[38;5;241m.\u001B[39mEMBEDDINGS: embeddings,\n\u001B[1;32m    341\u001B[0m         },\n\u001B[1;32m    342\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/base/embeddings/base.py:228\u001B[0m, in \u001B[0;36mBaseEmbedding._get_text_embeddings\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03mEmbed the input sequence of text synchronously.\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \n\u001B[1;32m    225\u001B[0m \u001B[38;5;124;03mSubclasses can implement this method if batch queries are supported.\u001B[39;00m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;66;03m# Default implementation just loops over _get_text_embedding\u001B[39;00m\n\u001B[0;32m--> 228\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_text_embedding(text) \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m texts]\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/base/embeddings/base.py:228\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03mEmbed the input sequence of text synchronously.\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \n\u001B[1;32m    225\u001B[0m \u001B[38;5;124;03mSubclasses can implement this method if batch queries are supported.\u001B[39;00m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;66;03m# Default implementation just loops over _get_text_embedding\u001B[39;00m\n\u001B[0;32m--> 228\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_text_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m texts]\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py:670\u001B[0m, in \u001B[0;36mBoundFunctionWrapper.__call__\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    667\u001B[0m             wrapped \u001B[38;5;241m=\u001B[39m PartialCallableObjectProxy(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__wrapped__, instance)\n\u001B[1;32m    668\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_wrapper(wrapped, instance, newargs, kwargs)\n\u001B[0;32m--> 670\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_self_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__wrapped__\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_self_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m            \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_binding \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcallable\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_instance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    675\u001B[0m         \u001B[38;5;66;03m# This situation can occur where someone is calling the\u001B[39;00m\n\u001B[1;32m    676\u001B[0m         \u001B[38;5;66;03m# instancemethod via the class type and passing the instance as\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    679\u001B[0m         \u001B[38;5;66;03m# the wrapped function using a partial so the wrapper doesn't\u001B[39;00m\n\u001B[1;32m    680\u001B[0m         \u001B[38;5;66;03m# see anything as being different.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    318\u001B[0m             _logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 321\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio\u001B[38;5;241m.\u001B[39mFuture):\n\u001B[1;32m    323\u001B[0m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[1;32m    324\u001B[0m         new_future \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mensure_future(result)\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/embeddings/fastembed/base.py:91\u001B[0m, in \u001B[0;36mFastEmbedEmbedding._get_text_embedding\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     89\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model\u001B[38;5;241m.\u001B[39mpassage_embed(text))\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 91\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embeddings[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/fastembed/text/text_embedding.py:107\u001B[0m, in \u001B[0;36mTextEmbedding.embed\u001B[0;34m(self, documents, batch_size, parallel, **kwargs)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membed\u001B[39m(\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     87\u001B[0m     documents: Union[\u001B[38;5;28mstr\u001B[39m, Iterable[\u001B[38;5;28mstr\u001B[39m]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m     91\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterable[np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m     92\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;124;03m    Encode a list of documents into list of embeddings.\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;124;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m        List of embeddings, one per document\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39membed(documents, batch_size, parallel, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/fastembed/text/onnx_embedding.py:262\u001B[0m, in \u001B[0;36mOnnxTextEmbedding.embed\u001B[0;34m(self, documents, batch_size, parallel, **kwargs)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membed\u001B[39m(\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    242\u001B[0m     documents: Union[\u001B[38;5;28mstr\u001B[39m, Iterable[\u001B[38;5;28mstr\u001B[39m]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    246\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterable[np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m    247\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;124;03m    Encode a list of documents into list of embeddings.\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;124;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;124;03m        List of embeddings, one per document\u001B[39;00m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 262\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embed_documents(\n\u001B[1;32m    263\u001B[0m         model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name,\n\u001B[1;32m    264\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache_dir),\n\u001B[1;32m    265\u001B[0m         documents\u001B[38;5;241m=\u001B[39mdocuments,\n\u001B[1;32m    266\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m    267\u001B[0m         parallel\u001B[38;5;241m=\u001B[39mparallel,\n\u001B[1;32m    268\u001B[0m         providers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproviders,\n\u001B[1;32m    269\u001B[0m         cuda\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcuda,\n\u001B[1;32m    270\u001B[0m         device_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_ids,\n\u001B[1;32m    271\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    272\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/fastembed/text/onnx_text_model.py:118\u001B[0m, in \u001B[0;36mOnnxTextModel._embed_documents\u001B[0;34m(self, model_name, cache_dir, documents, batch_size, parallel, providers, cuda, device_ids, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_onnx_model()\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m iter_batch(documents, batch_size):\n\u001B[0;32m--> 118\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_process_onnx_output(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m parallel \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/fastembed/text/onnx_text_model.py:85\u001B[0m, in \u001B[0;36mOnnxTextModel.onnx_embed\u001B[0;34m(self, documents, **kwargs)\u001B[0m\n\u001B[1;32m     79\u001B[0m     onnx_input[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[1;32m     80\u001B[0m         [np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(e), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint64) \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m input_ids], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint64\n\u001B[1;32m     81\u001B[0m     )\n\u001B[1;32m     83\u001B[0m onnx_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preprocess_onnx_input(onnx_input, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 85\u001B[0m model_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mONNX_OUTPUT_NAMES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monnx_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m OnnxOutputContext(\n\u001B[1;32m     87\u001B[0m     model_output\u001B[38;5;241m=\u001B[39mmodel_output[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m     88\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39monnx_input\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m, attention_mask),\n\u001B[1;32m     89\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39monnx_input\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m, input_ids),\n\u001B[1;32m     90\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[1;32m    218\u001B[0m     output_names \u001B[38;5;241m=\u001B[39m [output\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_meta]\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_feed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m C\u001B[38;5;241m.\u001B[39mEPFail \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_fallback:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "client = qdrant_client.QdrantClient(host=\"localhost\", port=6333, timeout=60)\n",
    "vector_store = QdrantVectorStore(client=client,\n",
    "                                 collection_name=\"document_chat\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(docs,\n",
    "                                        storage_context=storage_context)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:58:13.160445Z",
     "start_time": "2024-12-11T01:55:14.885673Z"
    }
   },
   "id": "3650b2ab76ac9574"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.  Define the query engine and prompt template"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46574cbc14c0ce95"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=4,\n",
    "                                     node_postprocessors=[rerank])\n",
    "\n",
    "template = \"\"\"Context information is below.\n",
    "              ---------------------\n",
    "              {context_str}\n",
    "              ---------------------\n",
    "              Given the context information above I want you to think\n",
    "              step by step to answer the query in a crisp manner. Incase \n",
    "              you don't know the answer say 'I don't know!'.\n",
    "              \n",
    "              Query: {query_str}\n",
    "              \n",
    "              Answer:\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(template)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T23:41:53.410096Z",
     "start_time": "2024-12-10T23:41:53.402207Z"
    }
   },
   "id": "f33c2f42588b374e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Query the document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c56f91c7822b88f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "The structure of funding startups in batches contributed significantly to the success and growth of the Y Combinator (YC) program. Here's a step-by-step breakdown:\n\n1. **Isolation problem**: Founders often faced isolation, which is a major challenge when trying to build and grow a startup. Funding companies like YC allowed founders to connect with peers who understood their problems and were facing similar challenges.\n\n2. **Convenience for the founders**: By funding startups in batches, YC made it easier for them to work on multiple projects simultaneously. This allowed founders to scale more efficiently, which in turn led to better outcomes.\n\n3. **Experienced investors and experts**: The batch-funded model enabled YC to attract experienced investors and experts who were familiar with the startup space. These mentors helped founders refine their ideas and increase their chances of success.\n\n4. **Tight community and networking opportunities**: The Y Combinator's headquarters in Cambridge provided a unique opportunity for founders to connect with each other, share experiences, and learn from one another. This fostered a tight-knit community that supported each other's growth.\n\n5. **Scaling the fundraising process**: By funding startups in batches, YC simplified the fundraising process, reducing the time it took to find new investors. This allowed the program to scale more efficiently, which contributed to its growth and success.\n\n6. **Improved deal flow**: The batch-funded model enabled YC to identify deals that might not have been viable as individual investments. By focusing on larger, more promising companies, the program could increase its chances of making successful investments.\n\n7. **Data-driven decision-making**: The data generated by the batch-funded model helped YC make informed decisions about which startups to fund and which investors to pursue. This data-driven approach enabled the program to refine its investment strategy over time.\n\n8. **Increased accessibility for underrepresented groups**: By funding companies from diverse backgrounds, YC expanded its reach beyond traditional tech hubs like Silicon Valley. This diversity also led to a more inclusive community of founders, entrepreneurs, and investors.\n\n9. **Better customer relationships**: The batch-funded model enabled YC to establish strong relationships with the startups they funded. These connections helped the program deliver value to the customers, ultimately leading to increased adoption and revenue growth.\n\n10. **Enhanced reputation and credibility**: By demonstrating its ability to successfully fund and grow companies in batches, YC reinforced its reputation as a premier startup accelerator. This credibility helped attract more investors, mentors, and students to the program.\n\nIn summary, the structure of funding startups in batches was instrumental in contributing to the success and growth of the Y Combinator program and the startups involved."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"\"\"How did the structure of funding startups \n",
    "                                 in batches contribute to the success and \n",
    "                                 growth of the Y Combinator program and the\n",
    "                                 startups involved?\"\"\")\n",
    "                                 \n",
    "display(Markdown(str(response)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T23:44:28.098172Z",
     "start_time": "2024-12-10T23:43:21.072856Z"
    }
   },
   "id": "b6b2683bd8455339"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = DirectoryLoader(\"./docs/paul_graham/\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "documents = loader.load_and_split(text_splitter)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T00:08:13.262874Z",
     "start_time": "2024-12-11T00:08:07.553062Z"
    }
   },
   "id": "c8f24f4e3f1b4aa8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lc': 1,\n 'type': 'constructor',\n 'id': ['langchain', 'schema', 'document', 'Document'],\n 'kwargs': {'page_content': 'What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.',\n  'metadata': {'source': 'docs/paul_graham/what_i_worked_on.txt'}}}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].to_json()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T00:09:04.873499Z",
     "start_time": "2024-12-11T00:09:04.853141Z"
    }
   },
   "id": "e7699516787443a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create RAGAS to evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fd56416bde0118d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "generator_llm = Ollama(model=\"phi3:3.8b\")\n",
    "critic_llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T00:11:54.585271Z",
     "start_time": "2024-12-11T00:11:54.335114Z"
    }
   },
   "id": "ba3ea5a0e11dbf0b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "embedding nodes:   0%|          | 0/360 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2354ed5bfba84456b28e6f19391861f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3664561fada74dadb46e324b7e32b741"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 11\u001B[0m\n\u001B[1;32m      4\u001B[0m generator \u001B[38;5;241m=\u001B[39m TestsetGenerator\u001B[38;5;241m.\u001B[39mfrom_langchain(\n\u001B[1;32m      5\u001B[0m     generator_llm\u001B[38;5;241m=\u001B[39mgenerator_llm,\n\u001B[1;32m      6\u001B[0m     critic_llm\u001B[38;5;241m=\u001B[39mcritic_llm,\n\u001B[1;32m      7\u001B[0m     embeddings\u001B[38;5;241m=\u001B[39mollama_emb\n\u001B[1;32m      8\u001B[0m )\n\u001B[1;32m     10\u001B[0m distribution \u001B[38;5;241m=\u001B[39m {simple: \u001B[38;5;241m0.5\u001B[39m, reasoning: \u001B[38;5;241m0.25\u001B[39m, multi_context: \u001B[38;5;241m0.25\u001B[39m}\n\u001B[0;32m---> 11\u001B[0m testset \u001B[38;5;241m=\u001B[39m \u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_with_langchain_docs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mdistributions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdistribution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mraise_exceptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ragas/testset/generator.py:179\u001B[0m, in \u001B[0;36mTestsetGenerator.generate_with_langchain_docs\u001B[0;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;66;03m# chunk documents and add to docstore\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdocstore\u001B[38;5;241m.\u001B[39madd_documents(\n\u001B[1;32m    176\u001B[0m     [Document\u001B[38;5;241m.\u001B[39mfrom_langchain_document(doc) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m    177\u001B[0m )\n\u001B[0;32m--> 179\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistributions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdistributions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwith_debugging_logs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_debugging_logs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_async\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_async\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraise_exceptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraise_exceptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ragas/testset/generator.py:272\u001B[0m, in \u001B[0;36mTestsetGenerator.generate\u001B[0;34m(self, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001B[0m\n\u001B[1;32m    269\u001B[0m         total_evolutions \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 272\u001B[0m     test_data_rows \u001B[38;5;241m=\u001B[39m \u001B[43mexec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresults\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m test_data_rows:\n\u001B[1;32m    274\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ExceptionInRunner()\n",
      "File \u001B[0;32m~/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ragas/executor.py:132\u001B[0m, in \u001B[0;36mExecutor.results\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    130\u001B[0m executor_job\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 132\u001B[0m     \u001B[43mexecutor_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1033\u001B[0m, in \u001B[0;36mThread.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1030\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1032\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1033\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1035\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[1;32m   1037\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1049\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lock \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# already determined that the C code is done\u001B[39;00m\n\u001B[1;32m   1048\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_stopped\n\u001B[0;32m-> 1049\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1050\u001B[0m     lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=ollama_emb\n",
    ")\n",
    "\n",
    "distribution = {simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n",
    "testset = generator.generate_with_langchain_docs(documents,\n",
    "                                                 test_size=10,\n",
    "                                                 distributions=distribution,\n",
    "                                                 raise_exceptions=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:26:01.405323Z",
     "start_time": "2024-12-11T00:13:21.223913Z"
    }
   },
   "id": "9e13cb3fd44338d7"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:31:59.297094Z",
     "start_time": "2024-12-11T01:31:59.172886Z"
    }
   },
   "id": "29fcac793d3feae4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = testset.t0_pandas().dropna()\n",
    "test_df.to_scv('test_data_paul_graham.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "299085a103a0eaeb"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_data_paul_graham.csv', index_col = 0).dropna()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:39:14.264674Z",
     "start_time": "2024-12-11T01:39:14.209311Z"
    }
   },
   "id": "f18ec98e3db5827d"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            question  \\\n0  How did the shift to publishing on the web cha...   \n1  How does criticizing a project as a \"toy\" rese...   \n2  How did the structure of funding startups in b...   \n3  How can exploring different topics help in gen...   \n4  How does focusing consistently on something yo...   \n\n                                            contexts  \\\n0  [\"Wow, I thought, there's an audience. If I wr...   \n1  [\"[9] You can't usually get paid for doing exa...   \n2  ['The deal for startups was based on a combina...   \n3  [\"Talking or writing about the things you're i...   \n4  [\"The way to beat it is to stop occasionally a...   \n\n                                        ground_truth evolution_type  \\\n0  The shift to publishing on the web changed the...         simple   \n1  Criticizing a project as a 'toy' is similar to...         simple   \n2  Funding startups in batches allowed for conven...         simple   \n3  Exploring different topics can help in generat...         simple   \n4  Great work happens by focusing consistently on...         simple   \n\n                                            metadata  episode_done  \n0  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n1  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n2  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n3  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n4  [{'source': 'paul_graham/how_to_do_great_thing...          True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>contexts</th>\n      <th>ground_truth</th>\n      <th>evolution_type</th>\n      <th>metadata</th>\n      <th>episode_done</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How did the shift to publishing on the web cha...</td>\n      <td>[\"Wow, I thought, there's an audience. If I wr...</td>\n      <td>The shift to publishing on the web changed the...</td>\n      <td>simple</td>\n      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How does criticizing a project as a \"toy\" rese...</td>\n      <td>[\"[9] You can't usually get paid for doing exa...</td>\n      <td>Criticizing a project as a 'toy' is similar to...</td>\n      <td>simple</td>\n      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How did the structure of funding startups in b...</td>\n      <td>['The deal for startups was based on a combina...</td>\n      <td>Funding startups in batches allowed for conven...</td>\n      <td>simple</td>\n      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How can exploring different topics help in gen...</td>\n      <td>[\"Talking or writing about the things you're i...</td>\n      <td>Exploring different topics can help in generat...</td>\n      <td>simple</td>\n      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How does focusing consistently on something yo...</td>\n      <td>[\"The way to beat it is to stop occasionally a...</td>\n      <td>Great work happens by focusing consistently on...</td>\n      <td>simple</td>\n      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:39:17.940170Z",
     "start_time": "2024-12-11T01:39:17.872576Z"
    }
   },
   "id": "95149ea40265037f"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(47, 6)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:39:51.815425Z",
     "start_time": "2024-12-11T01:39:51.725089Z"
    }
   },
   "id": "e210bc2df239b690"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "question          0\ncontexts          0\nground_truth      0\nevolution_type    0\nmetadata          0\nepisode_done      0\ndtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:40:33.507504Z",
     "start_time": "2024-12-11T01:40:33.370495Z"
    }
   },
   "id": "c1d262992fbdc84c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the RAG pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87b4ef6f80a898c3"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def generate_response(query_engine, question):\n",
    "    response = query_engine.query(question)\n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"contexts\": [c.node.get_content() for c in response.source_nodes],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:40:42.348271Z",
     "start_time": "2024-12-11T01:40:42.240090Z"
    }
   },
   "id": "3a90ffd85360b264"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "test_questions = test_df[\"question\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:46:14.972206Z",
     "start_time": "2024-12-11T01:46:14.920323Z"
    }
   },
   "id": "a063460b75242590"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_backends/sync.py\", line 128, in read\n",
      "    return self._sock.recv(max_bytes)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/t3/9tlz3sdn1z30yh45f615_6rr0000gn/T/ipykernel_77776/2864418575.py\", line 1, in <module>\n",
      "    generate_response(query_engine, test_questions[0])\n",
      "  File \"/var/folders/t3/9tlz3sdn1z30yh45f615_6rr0000gn/T/ipykernel_77776/1328380831.py\", line 2, in generate_response\n",
      "    response = query_engine.query(question)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/base/base_query_engine.py\", line 52, in query\n",
      "    query_result = self._query(str_or_query_bundle)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/query_engine/retriever_query_engine.py\", line 179, in _query\n",
      "    response = self._response_synthesizer.synthesize(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/base.py\", line 241, in synthesize\n",
      "    response_str = self.get_response(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py\", line 43, in get_response\n",
      "    return super().get_response(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py\", line 179, in get_response\n",
      "    response = self._give_response_single(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py\", line 241, in _give_response_single\n",
      "    program(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py\", line 85, in __call__\n",
      "    answer = self._llm.predict(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/llms/llm.py\", line 596, in predict\n",
      "    chat_response = self.chat(messages)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/llms/callbacks.py\", line 173, in wrapped_llm_chat\n",
      "    f_return_val = f(_self, messages, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/llms/ollama/base.py\", line 306, in chat\n",
      "    response = self.client.chat(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ollama/_client.py\", line 332, in chat\n",
      "    return self._request(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ollama/_client.py\", line 177, in _request\n",
      "    return cls(**self._request_raw(*args, **kwargs).json())\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ollama/_client.py\", line 118, in _request_raw\n",
      "    r = self._client.request(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 837, in request\n",
      "    params: QueryParamTypes | None = None,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 926, in send\n",
      "    except BaseException as exc:\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response.read()\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    if follow_redirects:\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    request.method,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    httpcore.ProtocolError: ProtocolError,\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "generate_response(query_engine, test_questions[0]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:50:25.959266Z",
     "start_time": "2024-12-11T01:48:15.056761Z"
    }
   },
   "id": "3fae2ca6697c68fd"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/47 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99c5623f7b0d4eda9b06ae1308fa8ef6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_backends/sync.py\", line 128, in read\n",
      "    return self._sock.recv(max_bytes)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/t3/9tlz3sdn1z30yh45f615_6rr0000gn/T/ipykernel_77776/939419950.py\", line 6, in <module>\n",
      "    responses = [generate_response(query_engine, q) for q in tqdm(test_questions)]\n",
      "  File \"/var/folders/t3/9tlz3sdn1z30yh45f615_6rr0000gn/T/ipykernel_77776/939419950.py\", line 6, in <listcomp>\n",
      "    responses = [generate_response(query_engine, q) for q in tqdm(test_questions)]\n",
      "  File \"/var/folders/t3/9tlz3sdn1z30yh45f615_6rr0000gn/T/ipykernel_77776/1328380831.py\", line 2, in generate_response\n",
      "    response = query_engine.query(question)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/base/base_query_engine.py\", line 52, in query\n",
      "    query_result = self._query(str_or_query_bundle)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/query_engine/retriever_query_engine.py\", line 179, in _query\n",
      "    response = self._response_synthesizer.synthesize(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/base.py\", line 241, in synthesize\n",
      "    response_str = self.get_response(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py\", line 43, in get_response\n",
      "    return super().get_response(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py\", line 179, in get_response\n",
      "    response = self._give_response_single(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py\", line 241, in _give_response_single\n",
      "    program(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py\", line 85, in __call__\n",
      "    answer = self._llm.predict(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/llms/llm.py\", line 596, in predict\n",
      "    chat_response = self.chat(messages)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/wrapt/wrappers.py\", line 670, in __call__\n",
      "    return self._self_wrapper(self.__wrapped__, self._self_instance,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/core/llms/callbacks.py\", line 173, in wrapped_llm_chat\n",
      "    f_return_val = f(_self, messages, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/llama_index/llms/ollama/base.py\", line 306, in chat\n",
      "    response = self.client.chat(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ollama/_client.py\", line 332, in chat\n",
      "    return self._request(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ollama/_client.py\", line 177, in _request\n",
      "    return cls(**self._request_raw(*args, **kwargs).json())\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/ollama/_client.py\", line 118, in _request_raw\n",
      "    r = self._client.request(*args, **kwargs)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 837, in request\n",
      "    params: QueryParamTypes | None = None,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 926, in send\n",
      "    except BaseException as exc:\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response.read()\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    if follow_redirects:\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    request.method,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    httpcore.ProtocolError: ProtocolError,\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/annaryzhokhina/PycharmProjects/RAG/venv/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "test_questions = test_df[\"question\"].values\n",
    "\n",
    "responses = [generate_response(query_engine, q) for q in tqdm(test_questions)]\n",
    "\n",
    "dataset_dict = {\n",
    "    \"question\": test_questions,\n",
    "    \"answer\": [response[\"answer\"] for response in responses],\n",
    "    \"contexts\": [response[\"contexts\"] for response in responses],\n",
    "    \"ground_truth\": test_df[\"ground_truth\"].values.tolist(),\n",
    "}\n",
    "\n",
    "ragas_eval_dataset = Dataset.from_dict(dataset_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T01:43:12.325279Z",
     "start_time": "2024-12-11T01:40:45.766152Z"
    }
   },
   "id": "edf4f1a7e3fe2d64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5fc48ee38c0a8fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = [faithfulness, answer_correctness,\n",
    "           context_recall, context_precision]\n",
    "\n",
    "critic_llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "evaluation_result = evaluate(\n",
    "    llm=critic_llm,\n",
    "    embeddings=ollama_emb,\n",
    "    dataset=ragas_eval_dataset,\n",
    "    metrics=metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c7416dea449b340"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_scores_df = pd.DataFrame(evaluation_result.scores)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bc74283ebacb733"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
